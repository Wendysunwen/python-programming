{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Programming\n",
    "\n",
    "**Chapter 6 : Data Handling with Python** \n",
    "\n",
    "Python is a fun language to learn, and really easy to pick up even if you are new to programming. In fact, quite often, Python is easier to pick up if you do not have any programming experience whatsoever. Python is high level programming language, targeted at students and professionals from diverse backgrounds.\n",
    "\n",
    "In this chapter, we will cover\n",
    "- Exploring CSV Dataset\n",
    "- Exploring JSON Files\n",
    "- Exploring HTML Tables\n",
    "\n",
    "**License Declaration** : Following the lead from the inspirations for this material, and the *spirit* of Python education and development, all modules of this work are licensed under the Creative Commons Attribution 3.0 Unported License. To view a copy of this license, visit http://creativecommons.org/licenses/by/3.0/.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring CSV Dataset\n",
    "\n",
    "Python is currently the language of choice for Data Analysis; the required libraries are `NumPy`, `Pandas`, `MatPlotLib`, `SeaBorn` and `Scikit-Learn`. In this example, we use the **\"Pokemon with stats\"** dataset from Kaggle, curated by *Alberto Barradas* (source: https://www.kaggle.com/abcsds/pokemon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV file into a DataFrame\n",
    "\n",
    "CSV is the easiest file format to handle in Pandas. Just use the `read_csv` function to import CSV into a Pandas `DataFrame`.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV Data\n",
    "pkmndata = pd.read_csv('files/pokemonData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first few rows of the dataset\n",
    "pkmndata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the dataset, as available on Kaggle, is as follows.\n",
    "Learn more : https://en.wikipedia.org/wiki/List_of_Pok%C3%A9mon\n",
    "\n",
    "> **\\#** : ID for each Pokemon (runs from 1 to 721)  \n",
    "> **Name** : Name of each Pokemon  \n",
    "> **Type 1** : Each Pokemon has a basic Type, this determines weakness/resistance to attacks  \n",
    "> **Type 2** : Some Pokemons are dual type and have a Type 2 value (set to nan otherwise)  \n",
    "> **Total** : Sum of all stats of a Pokemon, a general guide to how strong a Pokemon is  \n",
    "> **HP** : Hit Points, defines how much damage a Pokemon can withstand before fainting  \n",
    "> **Attack** : The base modifier for normal attacks by the Pokemon (e.g., scratch, punch etc.)  \n",
    "> **Defense** : The base damage resistance of the Pokemon against normal attacks  \n",
    "> **SP Atk** : Special Attack, the base modifier for special attacks (e.g. fire blast, bubble beam)  \n",
    "> **SP Def** : Special Defense, the base damage resistance against special attacks  \n",
    "> **Speed** : Determines which Pokemon attacks first each round  \n",
    "> **Generation** : Each Pokemon belongs to a certain Generation  \n",
    "> **Legendary** : Legendary Pokemons are powerful, rare, and hard to catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Data Type\n",
    "print(\"Data type : \", type(pkmndata))\n",
    "print(\"Data dims : \", pkmndata.shape)\n",
    "print()\n",
    "print(pkmndata.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on Numeric Variables \n",
    "\n",
    "You may want to check the basic statistical descriptions and visualize the corresponding statistical plots for *Numeric Variables* as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the numeric data variables\n",
    "numDF = pd.DataFrame(pkmndata[[\"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]])\n",
    "\n",
    "# Summary Statistics for all Variables\n",
    "numDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distributions of all variables\n",
    "f, axes = plt.subplots(6, 3, figsize=(18, 24))\n",
    "color_list = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\"]\n",
    "\n",
    "count = 0\n",
    "for var in numDF:\n",
    "    sb.boxplot(numDF[var], ax = axes[count,0], color = color_list[count])\n",
    "    sb.distplot(numDF[var], ax = axes[count,1], color = color_list[count])\n",
    "    sb.violinplot(numDF[var], ax = axes[count,2], color = color_list[count])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "print(numDF.corr())\n",
    "\n",
    "# Heatmap of the Correlation Matrix\n",
    "f, axes = plt.subplots(1, 1, figsize=(18, 12))\n",
    "sb.heatmap(numDF.corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\", annot_kws = {\"size\": 18}, cmap = \"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw pairs of variables against one another\n",
    "sb.pairplot(data = numDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on Categorical Variables\n",
    "\n",
    "You may also want to check the basic statistical descriptions and visualize the corresponding statistical plots for the *Categorical Variables*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generations in the Dataset\n",
    "print(\"Number of Generations :\", len(pkmndata[\"Generation\"].unique()))\n",
    "\n",
    "# Pokemons in each Generation\n",
    "print(pkmndata[\"Generation\"].value_counts())\n",
    "sb.catplot(y = \"Generation\", data = pkmndata, kind = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary Types in the Dataset\n",
    "print(\"Number of Primary Types :\", len(pkmndata[\"Type 1\"].unique()))\n",
    "\n",
    "# Pokemons of each Primary Type\n",
    "print(pkmndata[\"Type 1\"].value_counts())\n",
    "sb.catplot(y = \"Type 1\", data = pkmndata, kind = \"count\", height = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary Types in the Dataset\n",
    "print(\"Number of Secondary Types :\", len(pkmndata[\"Type 2\"].dropna().unique()))\n",
    "\n",
    "# Pokemons of each Secondary Type\n",
    "print(pkmndata[\"Type 2\"].dropna().value_counts())\n",
    "sb.catplot(y = \"Type 2\", data = pkmndata, kind = \"count\", height = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tasks\n",
    "\n",
    "- Do a similar exploration on the Kaggle Housing Prices dataset : https://www.kaggle.com/c/house-prices-advanced-regression-techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploring JSON Files\n",
    "\n",
    "If the dataset is in a standard JSON format, we may use the `read_json` function from Pandas. JSON is also a quite common data type in practice.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing JSON files\n",
    "cuisdata = pd.read_json('files/cuisineData.json')\n",
    "cuisdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the dataset, as available on Kaggle, is as follows.\n",
    "Learn more : https://www.kaggle.com/c/whats-cooking\n",
    "\n",
    "> **id** : ID for each Recipe     \n",
    "> **cuisine** : Type of Cuisine      \n",
    "> **ingredients** : the list of ingredients of each recipe (of variable length)     \n",
    "\n",
    "One such example is as follows. I have no clue what the dish is! Let me know if you can guess. ;-)\n",
    "\n",
    "    {\n",
    "        \"id\": 24717,\n",
    "        \"cuisine\": \"indian\",\n",
    "        \"ingredients\": [\n",
    "                        \"tumeric\",\n",
    "                        \"vegetable stock\",\n",
    "                        \"tomatoes\",\n",
    "                        \"garam masala\",\n",
    "                        \"naan\",\n",
    "                        \"red lentils\",\n",
    "                        \"red chili peppers\",\n",
    "                        \"onions\",\n",
    "                        \"spinach\",\n",
    "                        \"sweet potatoes\"\n",
    "                       ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the Data Type\n",
    "print(\"Data type : \", type(cuisdata))\n",
    "print(\"Data dims : \", cuisdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a single row\n",
    "cuisdata.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a single column\n",
    "cuisdata[\"ingredients\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a single element\n",
    "cuisdata.loc[0, \"ingredients\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tasks\n",
    "\n",
    "- Create a new column `ingredient_string` by joining all ingredients of each recipe together into a single string.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploring HTML Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing HTML file from the URL\n",
    "html_data = pd.read_html('https://en.wikipedia.org/wiki/List_of_actors_with_two_or_more_Academy_Awards_in_acting_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset you imported\n",
    "print(\"Data type : \", type(html_data))\n",
    "print(\"HTML tables : \", len(html_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the individual tables\n",
    "html_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the table as Pandas Dataframe\n",
    "awardsDF = pd.DataFrame(html_data[0])\n",
    "awardsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the statistics for Total awards\n",
    "awardsDF['Total awards'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the statistics for Total nominations\n",
    "awardsDF['Total nominations'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the relationship between nominations and awards\n",
    "sb.jointplot(x = awardsDF['Total nominations'], y = awardsDF['Total awards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tasks\n",
    "\n",
    "- Do a similar analysis on the Olympic 2016 medals : https://en.wikipedia.org/wiki/2016_Summer_Olympics_medal_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
